{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CreateML-Conversion.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN3qsFjc9402K2lQbVDWJpL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noahgift/Apple-CreateML-AutoML-Recipes/blob/main/CreateML_Conversion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPsAaacEzRV9"
      },
      "source": [
        "## Apple CreateML Conversion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvvLP-397jC6"
      },
      "source": [
        "#### Install coremltools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrZJ5rYMzHuD",
        "outputId": "f45d3082-fba0-4028-c9e5-0e4947b2b72d"
      },
      "source": [
        "!pip install coremltools"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting coremltools\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/b0/14c37edf39a9b32c2c9c7aa3e27ece4ef4f5b2dd2c950102661a106520f1/coremltools-4.1-cp37-none-manylinux1_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 5.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.20,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.19.5)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.7/dist-packages (from coremltools) (20.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from coremltools) (20.9)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.7.1)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from coremltools) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from coremltools) (4.41.1)\n",
            "Collecting attr\n",
            "  Downloading https://files.pythonhosted.org/packages/de/be/ddc7f84d4e087144472a38a373d3e319f51a6faf6e5fc1ae897173675f21/attr-0.3.1.tar.gz\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->coremltools) (2.4.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->coremltools) (1.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->coremltools) (56.0.0)\n",
            "Building wheels for collected packages: attr\n",
            "  Building wheel for attr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for attr: filename=attr-0.3.1-cp37-none-any.whl size=2458 sha256=f08c21216ada4df253eda3f778c2582986c2b648a8b4b6b1593feaa2ac6b01e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f0/96/9b/1f8892a707d17095b5a6eab0275da9d39e68e03a26aee2e726\n",
            "Successfully built attr\n",
            "Installing collected packages: attr, coremltools\n",
            "Successfully installed attr-0.3.1 coremltools-4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BV3Z9YlXzO6Y",
        "outputId": "275d2f00-a0c7-4d80-be21-d13b7f67ab9c"
      },
      "source": [
        "import coremltools"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:scikit-learn version 0.22.2.post1 is not supported. Minimum required version: 0.17. Maximum required version: 0.19.2. Disabling scikit-learn conversion API.\n",
            "WARNING:root:TensorFlow version 2.4.1 detected. Last version known to be fully compatible is 2.3.1 .\n",
            "WARNING:root:Keras version 2.4.3 detected. Last version known to be fully compatible of Keras is 2.2.4 .\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn-Zz4i67mAR"
      },
      "source": [
        "#### Download Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjRybZvK7rGX"
      },
      "source": [
        "Based off official quickstart guide:  https://coremltools.readme.io/docs/introductory-quickstart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zLoOiBz6IR2",
        "outputId": "69834491-d8e4-4fc9-ac8a-7d150f03b174"
      },
      "source": [
        "import tensorflow as tf # TF 2.2.0\n",
        "\n",
        "# Download MobileNetv2 (using tf.keras)\n",
        "keras_model = tf.keras.applications.MobileNetV2(\n",
        "    weights=\"imagenet\", \n",
        "    input_shape=(224, 224, 3,),\n",
        "    classes=1000,\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
            "14540800/14536120 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcW4U1G_6RXC"
      },
      "source": [
        "# Download class labels (from a separate file)\n",
        "import urllib\n",
        "label_url = 'https://storage.googleapis.com/download.tensorflow.org/data/ImageNetLabels.txt'\n",
        "class_labels = urllib.request.urlopen(label_url).read().splitlines()\n",
        "class_labels = class_labels[1:] # remove the first class which is background\n",
        "assert len(class_labels) == 1000\n",
        "\n",
        "# make sure entries of class_labels are strings\n",
        "for i, label in enumerate(class_labels):\n",
        "  if isinstance(label, bytes):\n",
        "    class_labels[i] = label.decode(\"utf8\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YJlVZvg6S-T"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEQADzxk8AZo"
      },
      "source": [
        "#### Convert Model and Set model metadata"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOBWjcTi8BvN",
        "outputId": "604f8f7a-eafb-48d9-93b6-e74c14bbe73d"
      },
      "source": [
        "import coremltools as ct\n",
        "\n",
        "# Define the input type as image, \n",
        "# set pre-processing parameters to normalize the image \n",
        "# to have its values in the interval [-1,1] \n",
        "# as expected by the mobilenet model\n",
        "image_input = ct.ImageType(shape=(1, 224, 224, 3,),\n",
        "                           bias=[-1,-1,-1], scale=1/127)\n",
        "\n",
        "# set class labels\n",
        "classifier_config = ct.ClassifierConfig(class_labels)\n",
        "\n",
        "# Convert the model using the Unified Conversion API\n",
        "model = ct.convert(\n",
        "    keras_model, inputs=[image_input], classifier_config=classifier_config,\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running TensorFlow Graph Passes: 100%|██████████| 5/5 [00:00<00:00,  7.36 passes/s]\n",
            "Converting Frontend ==> MIL Ops: 100%|██████████| 426/426 [00:01<00:00, 391.38 ops/s]\n",
            "Running MIL optimization passes: 100%|██████████| 18/18 [00:00<00:00, 18.53 passes/s]\n",
            "Translating MIL ==> MLModel Ops: 100%|██████████| 747/747 [00:00<00:00, 1339.05 ops/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a52pS9788JH1"
      },
      "source": [
        "# Set feature descriptions (these show up as comments in XCode)\n",
        "model.input_description[\"input_1\"] = \"Input image to be classified\"\n",
        "model.output_description[\"classLabel\"] = \"Most likely image category\"\n",
        "\n",
        "# Set model author name\n",
        "model.author = '\"Original Paper: Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen'\n",
        "\n",
        "# Set the license of the model\n",
        "model.license = \"Please see https://github.com/tensorflow/tensorflow for license information, and https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet for the original source of the model.\"\n",
        "\n",
        "# Set a short description for the Xcode UI\n",
        "model.short_description = \"Detects the dominant objects present in an image from a set of 1001 categories such as trees, animals, food, vehicles, person etc. The top-1 accuracy from the original publication is 74.7%.\"\n",
        "\n",
        "# Set a version for the model\n",
        "model.version = \"2.0\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzuwehE49dWN"
      },
      "source": [
        "#### Save the Model Out"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6d_XB8T9ez1"
      },
      "source": [
        "# Save model\n",
        "model.save(\"MobileNetV2.mlmodel\")\n",
        "                  \n",
        "# Load a saved model\n",
        "loaded_model = ct.models.MLModel(\"MobileNetV2.mlmodel\")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OAT136bK8N_"
      },
      "source": [
        "Download the model and open with XCode"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4BDG_8JK_hL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}